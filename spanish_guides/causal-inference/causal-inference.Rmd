---
output: 
  html_document:
    toc: true
    theme: journal
---

<!-- title: "10 Things You Need to Know About Causal Inference" -->
<!-- author: "Methods Guide Author: Macartan Humphreys" -->

Resumen
==

El fil√≥sofo David Lewis describi√≥ la causalidad como "algo que marca la diferencia, y esa diferencia que hace, debe ser la diferencia entre lo que fue y lo que hubiera sido sin ese algo".[^1] Esta es la interpretaci√≥n que dan a la causalidad la mayor√≠a de los experimentalistas. Aunque la definici√≥n parece simple, tiene muchas implicaciones sutiles. Aqu√≠ les presentamos diez ideas impl√≠citas en esta noci√≥n de causalidad que son importantes para el dise√±o de investigaci√≥n.^[Autor: Macartan Humphreys. Revisiones menores: Winston Lin y Donald P. Green, 24 de junio de 2016. Revisiones MH 6 de enero de 2020. Revisiones Anna Wilke de mayo de 2021. Esta gu√≠a es un documento din√°mico y est√° sujeta a actualizaci√≥n por parte de los miembros de EGAP; los colaboradores enumerados no son responsables de las ediciones posteriores.]


[^1]: Lewis, David. "Causation." The journal of philosophy (1973): 556-567.

1. Una afirmaci√≥n causal es un enunciado sobre lo que no sucedi√≥
==

Para la mayor√≠a de investigadores que realizan experimentos, el enunciado "$X$ caus√≥ $Y$" significa que $Y$ ocurri√≥ *y*  que no habr√≠a ocurrido si $X$ no hubiera estado presente. Esta definici√≥n requiere que tengamos una noci√≥n de lo que podr√≠a haber sucedido, pero no sucedi√≥.[^2] De manera similar, el "efecto" de $X$ en $Y$ se considera la diferencia entre el valor que $Y$ habr√≠a tomado dado un valor de $X$ y el valor que $Y$ habr√≠a tomado dado otro valor de $X$. Debido al enfoque en la diferencia de los resultados, este enfoque a veces se conoce como el enfoque de causalidad basado en "hacer diferencias" o en lo "contrafactual".

__Nota t√©cnica:__ Los estad√≠sticos emplean el marco de "salidas potenciales" para describir las relaciones contrafactuales. En este marco, dejamos que $Y_i(1)$ denote el valor que la unidad $i$ tomar√≠a bajo la condici√≥n uno (por ejemplo, si la unidad $i$ recibi√≥ un tratamiento) y $Y_i(0)$ el valor que habr√≠a sido observado en otra condici√≥n (por ejemplo, si la unidad $i$ no recibi√≥ el tratamiento). Un efecto causal del tratamiento para la unidad $i$ puede ser una simple diferencia de las salidas potenciales $œÑ_i = Y_i(1)‚àíY_(0)$. Un tratamiento tiene un efecto causal (positivo o negativo) en $Y$ para la unidad $i$ si $Y_i (1) ‚â† Y_i (0)$.



[^2]: Holland, Paul W. "Statistics and causal inference." Journal of the American Statistical Association 81.396 (1986): 945-960.

2. No hay relaci√≥n causal sin manipulaci√≥n.
==

La definici√≥n "contrafactual" de causalidad requiere que uno sea capaz de pensar qu√© valores podemos observar en diferentes condiciones. ¬øC√≥mo ser√≠an las cosas si se eligiera un partido en lugar de otro? Las declaraciones causales cotidianas a menudo no cumplen con este requisito en alguna de estas dos formas:

* Primero, algunas declaraciones no especifican condiciones contrafactuales claras. Por ejemplo, la afirmaci√≥n de que "la recesi√≥n fue causada por Wall Street" no apunta a un contrafactual obvio: ¬ødebemos considerar si habr√≠a habido una recesi√≥n si Wall Street no existiera? ¬øO es la afirmaci√≥n realmente una afirmaci√≥n sobre acciones particulares que Wall Street podr√≠a haber tomado pero no lo hizo? Si es as√≠, ¬øqu√© acciones? Es dif√≠cil evaluar la validez de tales declaraciones. Adem√°s, puede depender de qu√© condiciones contrafactuales est√©n impl√≠citas en una afirmaci√≥n.


* En segundo lugar, algunos enunciados implican condiciones contrafactuales que no son posibles de imaginar. Por ejemplo, la afirmaci√≥n de que Peter consigui√≥ el trabajo porque es Peter implica una consideraci√≥n de lo que habr√≠a sucedido si Peter no fuera Peter. Alternativamente, la afirmaci√≥n de que Peter consigui√≥ el trabajo porque es un hombre requiere considerar a Peter como algo diferente de un hombre. El problema es que los contrafactuales en estos casos implican un cambio no solo en la condici√≥n que enfrenta un individuo sino en el propio individuo.

Para evitar estos problemas, algunos estad√≠sticos instan a restringir las afirmaciones causales a los tratamientos que pueden manipularse, al menos en la imaginaci√≥n, y no necesariamente en la pr√°ctica.[^11] Por ejemplo, si bien podr√≠amos tener dificultades con la afirmaci√≥n de que Peter consigui√≥ el trabajo porque es hombre, no tendr√≠amos las mismas dificultades con la afirmaci√≥n de que Peter consigui√≥ el trabajo porque la agencia de contrataci√≥n pens√≥ que era hombre



[^11]: Holland, Paul W. "Statistics and causal inference." Journal of the American Statistical Association 81.396 (1986): 945-960.


3. Las causas no tienen por qu√© ser rivales.
==
Aunque nos podemos centrar en el efecto de una sola causa $X$ en un variable de inter√©s $Y$, generalmente no esperamos que $Y$ tenga solo una causa.[^5] Adem√°s, si sumamos los efectos causales de diferentes causas, no hay raz√≥n para esperar que sumen el 100%. Por lo tanto, no tiene mucho sentido tratar de "distribuir" los resultados entre diferentes factores causales. En otras palabras, las causas no tienen por qu√© ser rivales. La Asociaci√≥n Nacional del Rifle de Estados Unidos sostiene, por ejemplo, que las armas no matan a la gente, la gente mata a la gente. Esa afirmaci√≥n no tiene mucho sentido en el marco hipot√©tico. Quita las armas y no tendr√°s muertes por heridas de bala. Entonces las armas son una causa. Quita a la gente y tampoco tendr√°s muertes por heridas de bala, por lo que las personas tambi√©n son una causa. Dicho de otra manera, estos dos factores son simult√°neamente causas de los mismos resultados.


[^5]: Esto se conoce a veces como el "Problema de las causas excesivas".


4. $X$ puede causar $Y$ incluso si $X$ no es una condici√≥n necesaria o una condici√≥n suficiente para que $Y$ ocurra.
==
A menudo hablamos de relaciones causales en t√©rminos deterministas. Incluso la cita de Lewis en la parte superior de esta p√°gina parece sugerir una relaci√≥n determinista entre causas y efectos. A veces se piensa que las relaciones causales implican condiciones necesarias (para $Y$ que ocurra, $X$ tiene que suceder ); a veces se piensa que tales relaciones implican condiciones suficientes (si ocurre $X$, entonces ocurre $Y$). Pero una vez que hablamos de m√∫ltiples unidades, hay al menos dos formas en las que podemos pensar en que $X$ causa $Y$ incluso si $X$ no es una condici√≥n necesaria ni suficiente para $Y.$ La primera es reinterpretar todo en t√©rminos probabil√≠sticos: que $X$ cause $Y$, simplemente quiere decir que la probabilidad de $Y$ es mayor cuando $X$ est√° presente. Otra forma es permitir contingencias. Por ejemplo, $X$ puede causar $Y$ si la condici√≥n $Z$ est√° presente, pero no de otra manera.[^9]

[^9]: De acuerdo a Mackie, a veces se invoca la idea de condiciones "INUS" para capturar la dependencia de las causas de otras causas. Seg√∫n esta explicaci√≥n, una causa puede ser parte Insuficiente pero Necesaria de una condici√≥n que en s√≠ misma es Innecesaria pero Suficiente. Por ejemplo, marcar un n√∫mero de tel√©fono es una causa de contacto con alguien, ya que tener una conexi√≥n y marcar un n√∫mero es suficiente (S) para hacer una llamada telef√≥nica, mientras que marcar solo sin una conexi√≥n no ser√≠a suficiente (I), ni tener una conexi√≥n (N). Por supuesto, hay otras formas de contactar a alguien sin hacer llamadas telef√≥nicas (U). Mackie, John L. "El cemento del universo". Londres: Oxford Uni (1974).




5. Existe un problema fundamental de la inferencia causal
==
Si los efectos causales son enunciados sobre la diferencia entre lo que sucedi√≥ y lo que podr√≠a haber sucedido, entonces no los podemos medir. Malas noticias. De manera prospectiva, puede organizar las cosas para que pueda observar lo que sucede si alguien recibe un tratamiento o lo que sucede si no recibe el tratamiento. Sin embargo, para la misma persona nunca podr√° observar ambos resultados y, por lo tanto, tampoco la diferencia entre ellos. Esta incapacidad para observar efectos causales a nivel de la unidad de estudio a menudo se denomina "problema fundamental de la inferencia causal".


6. Usted puede estimar el efecto causal promedio aun cuando no pueda observar ning√∫n efecto causal individual.
==
Aunque no pueda observar si $X$ causa $Y$ para una unidad determinada, s√≠ es posible determinar si $X$ causa $Y$ en promedio. La idea clave aqu√≠ es que el efecto causal promedio es igual a la diferencia entre la variable de resultado promedio para todas las unidades, si todas est√°n en la condici√≥n de control y la variable de resultado promedio para todas las unidades si todas  est√°n en la condici√≥n de tratamiento. Muchas estrategias para la identificaci√≥n causal (ver [10 estrategias para determinar si X caus√≥ Y](http://egap.org/resource/10-strategies-for-figuring-out-if-x-caused-y)) se enfocan en formas de aprender acerca de estas salidas potenciales promedio.^[__Nota t√©cnica:__ La idea t√©cnica clave es que la diferencia de promedios es la misma que el promedio de diferencias. Es decir, usando el "operador de expectativas", $ùîº(œÑ_i) = ùîº (Y_i (1) ‚àíY_i (0)) = ùîº(Y_i (1)) - ùîº(Y_i (0))$. Los t√©rminos dentro del operador de esperanzas en la segunda cantidad no se pueden estimar, pero los t√©rminos dentro de los operadores de expectativas en la tercera cantidad si se pueden ser estimados[^3] Vea la ilustraci√≥n [aqu√≠] (https://raw.githubusercontent.com/egap/ gu√≠as-m√©todos / maestro / inferencia-causal / PO.jpg).]




[10 cosas que debe saber sobre las pruebas de hip√≥tesis](https://egap.org/resource/10-things-to-know-about-hypothesis-testing/) nos muestra c√≥mo podemos aprender acerca de efectos causales individuales en vez de efectos promediodato el problema fundamental de la inferencia causal.

[^3]: Holland, Paul W. "Statistics and causal inference." Journal of the American Statistical Association 81.396 (1986): 945-960.

7. La estimaci√≥n del efecto causal promedio no requiere que los grupos de tratamiento y control sean id√©nticos.
==
Una estrategia que la gente usa para aprender acerca del efect causal promedio es crear grupos de tratamiento y control a trav√©s de la aleatorizaci√≥n (ver [10 estrategias para determinar si X caus√≥ Y](http://egap.org/resource/10-strategies-for- determinar-si-x-caus√≥-y)). Es com√∫n que algunos investigadores se  preocupen por que los grupos de tratamiento y control resultantes no sean similares en dimensiones relevantes.

La buena noticia es que la raz√≥n por la cual las diferencias en los resultados promedio entre los grupos de control y tratamiento asignados aleatoriamente capturan los efectos promedio del tratamiento (en valor esperado a trav√©s de aleatorizaciones repetidas dentro del mismo grupo de unidades) *no* se basa en que los grupos de tratamiento y control sean similares en las caracter√≠sticas observadas. Sino que se basa √∫nicamente en la idea de que, en promedio, los resultados en los grupos tratados y de control capturar√°n los resultados promedio para todas las unidades en el grupo experimental si estuvieran, respectivamente, en tratamiento o en control. En la pr√°ctica, los grupos de tratamiento y de control no ser√°n id√©nticos.[^10]

[^10]: Por esta raz√≥n usar las pruebas $t$ para verificar si "la asignaci√≥n aleatoria funcion√≥ bien" no tiene mucho sentido, al menos si se sabe que se sigui√≥ una procedimiento aleatorio: por simple chance, 1 de cada 20 de esas pruebas mostrar√° diferencias estad√≠sticamente detectables entre los grupos tratados y de control. Si existen dudas sobre si la asignaci√≥n aleatoria se realiz√≥ correctamente, estas pruebas se pueden utilizar para probar la hip√≥tesis de que los datos se generaron efectivamente mediante un procedimiento aleatorio. Esta √∫ltima raz√≥n para las pruebas de aleatorizaci√≥n puede ser especialmente importante en experimentos de campo donde las cadenas de comunicaci√≥n entre la persona que crea los n√∫meros aleatorios y la persona que implementa la asignaci√≥n del tratamiento son largas y complejas.


8. Correlaci√≥n no es igual a causalidad.
==
Una correlaci√≥n entre $X$ y $Y$ es un enunciado sobre las relaciones entre los valores reales de estas variables y no sobre la relaci√≥n entre los valores reales y los valores contrafactuales. Entonces las afirmaciones sobre causas y correlaciones no tienen mucho que ver entre s√≠. Las correlaciones positivas pueden ser consistentes con efectos causales positivos,  efectos causales nulos o incluso con efectos causales negativos. Por ejemplo, tomar medicamentos para la tos se correlaciona positivamente con la tos, pero es de esperar que tenga un efecto causal negativo sobre la tos.^[__Nota t√©cnica:__ Sea $D_i$ un indicador de si la unidad $i$ ha recibido un tratamiento o no. Entonces la diferencia en los resultados promedio entre los que reciben el tratamiento y los que no lo reciben se puede escribir como $\frac{‚àë_i D_i √ó Y_i (1)} {‚àë_iD_i} - \frac {‚àë_i(1 ‚àí D_i) √ó Y_i (0)}{‚àë_i (1 ‚àí D_i)}$. Sin informaci√≥n sobre c√≥mo se asign√≥ el tratamiento, no hay mucho por decir sobre si esta diferencia es un buen estimador del efecto promedio del tratamiento. Es decir, de la diferencia en las salidas potenciales promedio de las unidades en el grupo de tratamiento y control para todas las unidades. Lo que importa es si $\frac{‚àë_i D_i √ó Y_i (1)} {‚àë_iD_i $ es una buena estimaci√≥n de $\frac{‚àë_i 1 √ó Y_i (1)} {‚àë_i1}$ y si $\frac{‚àë_i (1 ‚àí D_i) √ó Y_i (0)}{‚àë_i(1 ‚àí D_i)}$ es una buena estimaci√≥n de $\frac{‚àë_i 1 √ó Y_i (0)} {‚àë_i1}$. Este puede ser el caso si los que recibieron tratamiento son una muestra representativa de todas las unidades, pero de lo contrario no hay raz√≥n para esperar que as√≠ sea.]



9. Si usted sabe que, en promedio, $A$ causa $ B $ y $B$ causa $C$, esto no significa que, en promedio, $A$ cause $C$.

==
Se podr√≠a esperar que si $A$ causa $B$ y $B$ causa $C$, entonces $A$ causa $C$.[^12] Pero no hay raz√≥n para creer que las relaciones causales promedio sean transitivas.  Para entender por qu√©, imagine que $A$ caus√≥ $B$ en los hombres pero no en las mujeres y $B$ caus√≥ $C$ en las mujeres pero no en los hombres. Entonces, en promedio, $A$ causa $B$ y $B$ causa $C$, pero es posible que no haya nadie para quien $A$ tenga un efecto en $C$ mediado por $B$.

[^ 12]: Enti√©ndase la expresi√≥n "$A$ causa $B$, en promedio" como "el efecto promedio de $A$ sobre $B$ es positivo".



10. Es m√°s f√°cil aprender sobre los "efectos de las causas" que aprender sobre las "causas de los efectos".
==
Aunque puedan parecer dos formas de decir exactamente lo mismo, existe una diferencia entre comprender cu√°l es el efecto de $X$ en $Y$ (los "efectos de una causa") y si  *el valor que tom√≥ $Y$* se debi√≥ a $X$ (la "causa de un efecto").[^6] Considere el siguiente ejemplo. Supongamos que realizamos un experimento con una muestra que contiene el mismo n√∫mero de hombres y mujeres. El experimento asigna aleatoriamente a hombres y mujeres a un tratamiento binario $X$ y mide una variable de inter√©s binaria $Y$. Adem√°s suponga que $X$ tiene un efecto positivo de 1 para todos los hombres, es decir, el resultado potencial del control de los hombres es cero ($Y_i(0) = 0$) y la salida potencial cuando son tratados es uno ($Y_i(1) = 1$). Para todas las mujeres, $X$ tiene un efecto negativo de $-1$, es decir, la salida potencial de las mujeres bajo el control es uno ($Y_i (0) = 1 $) y su salida potencial cuando son tratadas es cero ($Y_i (1) = 0$)  En este ejemplo, el efecto promedio de $X$ en $ Y $ es cero. Pero la raz√≥n para que los participantes en el grupo de tratamiento tengan $Y = 1$,  es *porque* $X = 1$. De manera similar, todos los participantes en el grupo de tratamiento con $Y = 0$, tienen  $Y = 0$ *porque* $X = 1$. Los experimentos nos permiten obtener una respuesta exacta a la pregunta sobre los "efectos de una causa", pero en general no es posible obtener una respuesta exacta a la pregunta sobre la "causa de un efecto".[^ 7]


[^ 6]: A veces se reinterpreta la pregunta "causas de los efectos" en el sentido de: ¬øcu√°les son las causas que tienen efectos sobre las variable de resultado? V√©ase Andrew Gelman and Guido Imbens, "Why ask why?
Forward causal inference and reverse causal questions", NBER Working Paper No. 19614 (Nov. 2013).
[^7]: Ver, por ejemplo, Tian, J., Pearl, J. 2000. ‚ÄúProbabilities of Causation: Bounds and Identification.‚Äù Annals of Mathematics and Artificial Intelligence 28:287‚Äì313.
.
