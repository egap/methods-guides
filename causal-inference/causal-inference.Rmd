---
output: 
  html_document:
    toc: true
    theme: journal
---

<!-- title: "10 choses √† savoir sur l'inf√©rence causale" -->
<!-- author: "Auteur du guide des m√©thodes: Macartan Humphreys" -->

R√©sum√©
==
Le philosophe David Lewis a d√©crit la causalit√© comme "quelque chose qui fait une diff√©rence, et cette diff√©rence doit √™tre une diff√©rence par rapport √† ce qui se serait pass√© sans elle".[^1]
Ceci est l'interpr√©tation de la causalit√© pour la plupart des exp√©rimentalistes. M√™me si la d√©finition semble simple, elle a de nombreuses implications subtiles.
Voici dix id√©es impliqu√©es par cette notion de causalit√© qui importent pour la conception de recherche.
^[Auteur d'origine : Macartan Humphreys. R√©visions mineures : Winston Lin et Donald P. Green, 24 juin 2016. R√©visions MH 6 janvier 2020. R√©visions Anna Wilke mai 2021.
Le guide est un document vivant et peut √™tre mis √† jour par les membres de EGAP √† tout moment ; les contributeurs r√©pertori√©s ne sont pas responsables des modifications ult√©rieures.]

[^1]: Lewis, David. "Causation." The journal of philosophy (1973): 556-567.

1. Une assertion causale est une d√©claration sur ce qui ne s'est pas produit.
==
Pour la plupart des exp√©rimentalistes, la d√©claration "$X$ a caus√© $Y$" signifie que $Y$ est pr√©sent *et* $Y$ n'aurait pas √©t√© pr√©sent si $X$ n'avait pas √©t√© pr√©sent.
Cette d√©finition requiert une notion de ce qui aurait pu arriver, mais ne s'est pas produit.[^2]
De m√™me, "l'effet" de $X$ sur $Y$ est la diff√©rence entre la valeur que $Y$ aurait prise √©tant donn√© une valeur de $X$ et la valeur que $Y$ aurait prise √©tant donn√© une autre valeur de $X$.
En raison de l'accent mis sur les diff√©rences entre les r√©sultats, cette approche est parfois appel√©e approche "des diff√©rences"¬†ou "contrefactuelle" de la causalit√©.

__Note technique:__
Les statisticiens emploient le cadre des "r√©sultats potentiels" pour d√©crire les relations contrefactuelles.
Dans ce cadre, $Y_i(1)$ d√©signe le r√©sultat pour l'unit√© $i$ qui serait observ√© sous une condition (par exemple, si l'unit√© $i$ a re√ßu un traitement)
et $Y_i(0)$ d√©signe le r√©sultat qui serait observ√© dans une autre condition (par exemple, si l'unit√© $i$ n'a pas re√ßu le traitement).
Un effet causal du traitement pour l'unit√© $i$ pourrait √™tre une simple diff√©rence des r√©sultats potentiels $œÑ_i=Y_i(1)‚àíY_i(0)$.
Un traitement a un effet causal (positif ou n√©gatif) sur $Y$ pour l'unit√© $i$ si $Y_i(1)‚â†Y_i(0)$.

[^2]: Holland, Paul W. "Statistics and causal inference." Journal of the American Statistical Association 81.396 (1986): 945-960.

2. Pas de causalit√© sans manipulation.
==
La d√©finition "contrefactuelle" de la causalit√© exige que l'on soit capable de r√©fl√©chir aux r√©sultats qui peuvent entra√Æner des conditions diff√©rentes.
Quelle serait la situation si un parti plut√¥t qu'un autre √©tait √©lu ?
Les d√©clarations causales de tous les jours ne r√©pondent souvent pas √† cette exigence de l'une des deux mani√®res suivantes.

* Premi√®rement, certaines d√©clarations ne pr√©cisent pas de conditions contrefactuelles claires.
Par exemple, l'affirmation selon laquelle "la r√©cession a √©t√© caus√©e par Wall Street" n'indique pas de contrefactuel √©vident
--- devons-nous examiner s'il y aurait eu une r√©cession si Wall Street n'avait pas exist√© ?
Ou est-ce une d√©claration sur des d√©cisions particuli√®res que Wall Street aurait pu prendre mais n'a pas prises ?
Si oui, quelles d√©cisions ? La validit√© de telles d√©clarations est difficile √† √©valuer et peut d√©pendre des conditions contrefactuelles impliqu√©es par une d√©claration.

* Deuxi√®mement, certaines d√©clarations impliquent des conditions contrefactuelles qui ne peuvent √™tre imagin√©es.
Par exemple, l'affirmation selon laquelle Peter a obtenu le poste parce qu'il est Peter implique une consid√©ration de ce qui se serait pass√© si Peter n'√©tait pas Peter.
Alternativement, l'affirmation selon laquelle Peter a obtenu le poste parce qu'il est un homme n√©cessite de consid√©rer Peter comme autre qu'un homme.
Le probl√®me est que les contrefactuels dans ces cas impliquent un changement non seulement de la condition √† laquelle fait face un individu, mais de l'individu lui-m√™me.

Pour √©viter de tels probl√®mes, certains statisticiens recommandent de restreindre les assertions causales aux traitements qui peuvent en th√©orie (pas n√©cessairement en pratique) √™tre manipul√©s.[^111]
Par exemple, alors que nous pourrions avoir des difficult√©s avec l'affirmation selon laquelle Peter a obtenu le poste parce qu'il √©tait un homme, nous n'avons pas de telles difficult√©s avec l'affirmation selon laquelle Peter a obtenu le poste parce que l'agence de recrutement pensait qu'il √©tait un homme.

[^111]: Holland, Paul W. "Statistics and causal inference." Journal of the American Statistical Association 81.396 (1986): 945-960.

3. Les causes sont non rivales.
==

M√™me si nous pouvons nous concentrer sur l'effet d'une seule cause $X$ sur un r√©sultat $Y$, nous ne nous attendons g√©n√©ralement pas √† ce qu'il n'y ait qu'une seule cause de $Y$.[^5]
De plus, si vous additionnez les effets causaux de diff√©rentes causes, il n'y a aucune raison de s'attendre √† ce qu'ils totalisent 100 %.
Par cons√©quent, il ne sert √† rien d'essayer de "r√©partir" les r√©sultats entre diff√©rents facteurs de causalit√©.
En d'autres termes, les causes sont non rivales.
La National Rifle Association soutient, par exemple, que les armes √† feu ne tuent pas les gens, les gens tuent les gens.
Cette d√©claration n'a pas beaucoup de sens dans le cadre contrefactuel.
Enlevez les armes √† feu et vous n'aurez pas de morts par balles.
Les armes √† feu sont donc une cause.
Enlevez les gens et vous n'aurez pas non plus de d√©c√®s par balle, donc les gens sont aussi une cause.
En d'autres termes, ces deux facteurs sont simultan√©ment les causes des m√™mes r√©sultats.

[^5]: Certains appellent cela le "probl√®me des causes de prodigalit√©".


4. $X$ peut causer $Y$ m√™me si $X$ n'est pas une condition n√©cessaire ou une condition suffisante pour $Y$.
==
On parle souvent des relations causales en termes d√©terministes.
M√™me la citation de Lewis en haut de cette page semble sugg√©rer une relation d√©terministe entre les causes et les effets.
On pense parfois que les relations causales impliquent des conditions n√©cessaires (pour que $Y$ se produise, $X$ doit se produire); on pense parfois que de telles relations impliquent des conditions suffisantes (si $X$ se produit, alors $Y$ se produit).
Mais une fois que nous parlons d'unit√©s multiples, il y a au moins deux fa√ßons de penser que $X$ cause $Y$ m√™me si $X$ n'est ni une condition n√©cessaire ni une condition suffisante pour $Y$.
La premi√®re consiste √† tout r√©interpr√©ter en termes probabilistes : par $X$ cause $Y$, on entend simplement que la probabilit√© de $Y$ est plus √©lev√©e lorsque $X$ est pr√©sent.
Une autre consiste √† tenir compte des contingences --- par exemple, $X$ peut causer $Y$ si la condition $Z$ est pr√©sente, mais pas dans le cas contraire.[^9]

[^9]:
Mackie a pr√©sent√© l'id√©e de conditions dites "INSS" ("INUS" en anglais) pour capturer la d√©pendance des causes sur d'autres causes.
Une cause peut √™tre une partie *Insuffisante* mais *N√©cessaire* d'une condition qui est elle-m√™me *Superflue* mais *Suffisante*.
Par exemple, composer un num√©ro de t√©l√©phone est une cause de "contacter quelqu'un" car avoir une connexion et composer un num√©ro est suffisant (S) pour passer un appel t√©l√©phonique,
alors que composer seul sans connexion ne suffirait pas (I), ni avoir un connexion (N).
Il existe bien s√ªr d'autres moyens de contacter quelqu'un sans passer d'appels t√©l√©phoniques (S).
Mackie, John L. "The cement of the universe." London: Oxford Uni (1974).

5. Le probl√®me fondamental de l'inf√©rence causale.
==

Si les effets causaux sont des d√©clarations sur la diff√©rence entre ce qui s'est produit et ce qui aurait pu se produire, alors les effets causaux ne peuvent pas √™tre mesur√©s. Mauvaise nouvelle !
De mani√®re prospective, vous pouvez organiser les choses de mani√®re √† observer ce qui se passe si une personne re√ßoit un traitement ou ce qui se passe si elle ne re√ßoit pas le traitement.
Pourtant, pour la m√™me personne, vous ne pourrez jamais observer ces deux r√©sultats et leur diff√©rence.
Cette incapacit√© √† observer les effets causaux au niveau de l'unit√© est souvent appel√©e le "probl√®me fondamental de l'inf√©rence causale".

6. Vous pouvez estimer l'effet causal moyen m√™me si vous ne pouvez observer aucun effet causal individuel.
==
<<<<<<< HEAD
Even though you cannot observe whether $X$ causes $Y$ for any given unit, it can still be possible to figure out whether $X$ causes $Y$ on average. The key insight here is that the average causal effect equals the difference between the average outcome across all units if all units were in the control condition and the average outcome across all units if all units were in the treatment condition. Many strategies for causal identification (see [10 Strategies for Figuring Out If X Caused Y](https://egap.org/resource/10-strategies-for-figuring-out-if-x-caused-y)) focus on ways to learn about these average potential outcomes.^[__Technical Note:__ The key technical insight is that the difference of averages is the same as the average of differences. That is, using the "expectations operator," $ùîº(œÑ_i)=ùîº(Y_i(1)‚àíY_i(0))=ùîº(Y_i(1))‚àíùîº(Y_i(0))$. The terms inside the expectations operator in the second quantity cannot be estimated, but the terms inside the expectations operators in the third quantity can be.[^3] See illustration [here](https://raw.githubusercontent.com/egap/methods-guides/master/causal-inference/PO.jpg).]
=======
>>>>>>> 3d7c587345ebeff14883428a24a479622c4a78f7

M√™me si vous ne pouvez pas observer si $X$ cause $Y$ pour une unit√© donn√©e, il est peut-√™tre toujours possible de d√©terminer si $X$ cause $Y$ en moyenne.
L'effet causal moyen est √©gal √† la diff√©rence entre le r√©sultat moyen pour toutes les unit√©s si elles √©taient toutes dans la condition de contr√¥le et le r√©sultat moyen pour toutes les unit√©s si elles √©taient toutes dans la condition de traitement.
De nombreuses strat√©gies d'identification causale (voir [10 strat√©gies pour d√©terminer si X a caus√© Y](http://egap.org/resource/10-strategies-for-figuring-out-if-x-caused-y)) se concentrent sur des fa√ßons d'en savoir plus sur ces r√©sultats potentiels moyens.^[__Note technique¬†:__ La principale id√©e technique est que la diff√©rence des moyennes est la m√™me que la moyenne des diff√©rences.
C'est-√†-dire, en utilisant "l'op√©rateur d'esp√©rance", $ùîº(œÑ_i)=ùîº(Y_i(1)‚àíY_i(0))=ùîº(Y_i(1))‚àíùîº(Y_i(0))$.
Les termes √† l'int√©rieur de l'op√©rateur d'esp√©rance dans la deuxi√®me quantit√© ne peuvent pas √™tre estim√©s, mais les termes √† l'int√©rieur de l'op√©rateur d'esp√©rance dans la troisi√®me quantit√© peuvent l'√™tre.[^3]Voir l'illustration [ici](https://raw.githubusercontent.com/egap/ methodes-guides/master/causal-inference/PO.jpg).]

[10 choses √† savoir sur les tests d'hypoth√®se](https://egap.org/resource/10-things-to-know-about-hypothesis-testing/) d√©crit comment en savoir plus sur les effets causaux individuels plut√¥t que sur les effets causaux moyens √©tant donn√© le probl√®me fondamental de l'inf√©rence causale.

[^3]: Holland, Paul W. "Statistics and causal inference." Journal of the American Statistical Association 81.396 (1986): 945-960.

7. L'estimation de l'effet causal moyen ne n√©cessite pas que les groupes de traitement et de contr√¥le soient identiques.
==
<<<<<<< HEAD
One strategy that people use to learn about average causal effects is to create treatment and control groups through randomization (see [10 Strategies for Figuring Out If X Caused Y](https://egap.org/resource/10-strategies-for-figuring-out-if-x-caused-y)). When doing so, researchers sometimes worry if they find that the resulting treatment and control groups do not look the same along relevant dimensions.
=======
Une strat√©gie que les gens utilisent pour en savoir plus sur l'effet causal moyen consiste √† cr√©er des groupes de traitement et de contr√¥le par randomisation (voir [10 Strat√©gies pour d√©terminer si X a caus√© Y](http://egap.org/resource/10-strategies-for-figuring-out-if-x-caused-y)).
Ce faisant, les chercheurs s'inqui√®tent parfois s'ils constatent que les groupes de traitement et de contr√¥le qui en r√©sultent ne sont pas comparables sur certaines dimensions importantes.
>>>>>>> 3d7c587345ebeff14883428a24a479622c4a78f7

La bonne nouvelle est que l'argument expliquant pourquoi les diff√©rences dans les r√©sultats moyens entre les groupes de traitement et de contr√¥le assign√©s de mani√®re al√©atoire capturent l'effet moyen du traitement (en esp√©rance pour des randomisations r√©p√©t√©es au sein du m√™me groupe d'unit√©s) ne repose *pas* sur le fait que les groupes de traitement et de contr√¥le ont des caract√©ristiques observ√©es similaires.
Il repose uniquement sur l'id√©e que, en moyenne, les r√©sultats dans les groupes de traitement et de contr√¥le captureront les r√©sultats moyens pour toutes les unit√©s du groupe exp√©rimental si elles √©taient, respectivement, dans le traitement ou dans le contr√¥le.
En pratique, les groupes de traitement et de contr√¥le r√©els ne seront pas identiques.[^10]

[^10]: Pour cette raison, les tests-$t$ pour v√©rifier si "la randomisation a fonctionn√©" n'ont pas beaucoup de sens, du moins si vous savez qu'une proc√©dure randomis√©e a √©t√© suivie --- simplement par hasard, 1 test sur 20 montrera des diff√©rences statistiquement d√©tectables entre les groupes de traitement et de contr√¥le.
En cas de doute sur la mise en ≈ìuvre correcte d'une proc√©dure randomis√©e, ces tests peuvent √™tre utilis√©s pour tester l'hypoth√®se selon laquelle les donn√©es ont bien √©t√© g√©n√©r√©es par une proc√©dure randomis√©e.
Ces tests peuvent alors √™tre particuli√®rement importants pour des exp√©riences de terrain o√π les cha√Ænes de communication entre la personne randomisant et la personne mettant en ≈ìuvre l'assignation du traitement peuvent √™tre longues et complexes.

8. La corr√©lation n'est pas la causalit√©.
==

Une corr√©lation entre $X$ et $Y$ est une d√©claration sur les relations entre les r√©sultats r√©els, et non sur la relation entre les r√©sultats r√©els et les r√©sultats contrefactuels.
Ainsi, les d√©clarations sur les causes et les corr√©lations n'ont pas grand-chose √† voir les unes avec les autres.
Des corr√©lations positives peuvent √™tre coh√©rentes avec des effets causaux positifs, aucun effet causal ou m√™me des effets causaux n√©gatifs.
Par exemple, la prise de m√©dicaments contre la toux est positivement corr√©l√©e √† la toux mais a, esp√©rons-le, un effet causal n√©gatif sur la toux.[^11]

[^11]: __Note technique__: soit $D_i$ un indicateur pour savoir si l'unit√© $i$ a re√ßu un traitement ou non.
Alors, la diff√©rence des r√©sultats moyens entre ceux qui re√ßoivent le traitement et ceux qui ne le re√ßoivent pas peut s'√©crire $\frac{‚àë_i D_i√óY_i(1)}{‚àë_iD_i}‚àí\frac{‚àë_i (1‚àíD_i)√ó Y_i(0)}{‚àë_i (1‚àíD_i)}$.
En l'absence d'informations sur la mani√®re dont le traitement a √©t√© assign√©, nous ne pouvons pas dire si cette diff√©rence est un bon estimateur de l'effet moyen du traitement, c'est-√†-dire de la diff√©rence entre les r√©sultats potentiels moyens pour les groupes de traitement et de contr√¥le pour toutes les unit√©s.
Ce qui importe est de savoir si $\frac{‚àë_i D_i√óY_i(1)}{‚àë_iD_i}$ est une bonne estimation de $\frac{‚àë_i 1√óY_i(1)}{‚àë_i1}$ et si $\frac {‚àë_i (1‚àíD_i)√óY_i(0)}{‚àë_i (1‚àíD_i)}$ est une bonne estimation de $\frac{‚àë_i 1√óY_i(0)}{‚àë_i1}$.
Cela pourrait √™tre le cas si ceux qui ont re√ßu un traitement sont un √©chantillon repr√©sentatif de toutes les unit√©s, mais sinon il n'y a aucune raison de s'attendre √† ce qu'il le soit.

9. Si vous savez qu'en moyenne $A$ cause $B$ et $B$ cause $C$, cela ne veut pas dire qu'en moyenne $A$ cause $C$.
==

Vous pourriez vous attendre √† ce que si $A$ cause $B$ et $B$ cause $C$, alors $A$ cause $C$.[^12]
Mais il n'y a aucune raison que les relations causales moyennes soient transitives.
Imaginez que $A$ cause $B$ pour les hommes mais pas les femmes et $B$ cause $C$ pour les femmes mais pas les hommes.
Ensuite, en moyenne, $A$ cause $B$ et $B$ cause $C$, mais $A$ ne cause pas $C$ √† travers $B$.

[^12]: Interpr√©tez "$A$ cause $B$, en moyenne" comme "l'effet moyen de $A$ sur $B$ est positif".

10. Il est plus facile d'en apprendre davantage sur les "effets des causes" que sur les "causes des effets".
==

Bien que cela puisse sembler √™tre deux fa√ßons de dire la m√™me chose, il y a une diff√©rence entre comprendre quel est l'effet de $X$ sur $Y$ (les "effets d'une cause") et si un r√©sultat $Y$ √©tait *d√ª* √† une cause $X$ (la "cause d'un effet").[^6] Consid√©rez l'exemple suivant.
Supposons que nous menions une exp√©rience avec un √©chantillon qui contient un nombre √©gal d'hommes et de femmes.
L'exp√©rience assigne de mani√®re al√©atoire des hommes et des femmes √† un traitement binaire $X$ et mesure un r√©sultat binaire $Y$.
De plus, supposons que $X$ ait un effet positif de 1 pour tous les hommes, c'est-√†-dire
le r√©sultat potentiel de contr√¥le des hommes est de z√©ro, $Y_i(0) = 0$, et leur r√©sultat potentiel trait√© est de un, $Y_i(1) = 1$.
Pour toutes les femmes, $X$ a un effet n√©gatif de $-1$, c'est-√†-dire que le r√©sultat potentiel de contr√¥le des femmes est de un, $Y_i(0) = 1$, et leur r√©sultat potentiel trait√© est de z√©ro, $Y_i(1) = 0$.
Dans cet exemple, l'effet moyen de $X$ sur $Y$ est nul.
Mais pour tous les participants du groupe de traitement avec $Y=1$, il est vrai que $Y=1$ *car* $X=1$.
De m√™me, pour tous les participants du groupe de traitement avec $Y=0$, il est vrai que $Y=0$ *car* $X=1$.
L'exp√©rimentation peut obtenir une r√©ponse exacte √† la question sur les "effets d'une cause", mais il n'est g√©n√©ralement pas possible d'obtenir une r√©ponse exacte √† la question sur la "cause d'un effet".[^7]

[^6]: Certains r√©interpr√®tent la question des "causes des effets" comme suit¬†: quelles sont les causes qui ont des effets sur les r√©sultats. Voir Andrew Gelman and Guido Imbens, "Why ask why? Forward causal inference and reverse causal questions", NBER Working Paper No. 19614 (Nov. 2013).
[^7]: Voir, par exemple, Tian, J., Pearl, J. 2000. "Probabilities of Causation: Bounds and Identification." Annals of Mathematics and Artificial Intelligence 28:287‚Äì313.
