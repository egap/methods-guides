---
output: 
  html_document:
    toc: true
    theme: journal
---

<!-- title: "10 choses Ã  savoir sur l'infÃ©rence causale" -->
<!-- author: "Auteur du guide des mÃ©thodes: Macartan Humphreys" -->

Abstract
==
Le philosophe David Lewis a dÃ©crit la causalitÃ© comme "quelque chose qui fait une diffÃ©rence, et cette diffÃ©rence doit Ãªtre une diffÃ©rence par rapport Ã  ce qui se serait passÃ© sans elle."[^1] Ceci est l'interprÃ©tation de la causalitÃ© pour la plupart des expÃ©rimentalistes. MÃªme si la dÃ©finition semble simple, elle a de nombreuses implications subtiles. Voici dix idÃ©es impliquÃ©es par cette notion de causalitÃ© qui importent pour le design de recherche.
^[Originating author: Macartan Humphreys. Minor revisions: Winston Lin and Donald P. Green, 24 Jun 2016. Revisions MH 6 Jan 2020. Revisions Anna Wilke May 2021. The guide is a live document and subject to updating by EGAP members at any time; contributors listed are not responsible for subsequent edits.]

[^1]: Lewis, David. "Causation." The journal of philosophy (1973): 556-567.

1. Un postulat de causalitÃ© est une dÃ©claration sur ce qui ne s'est pas produit.
==
Pour la plupart des expÃ©rimentateurs, la dÃ©claration "$X$ a causÃ© $Y$" signifie que $Y$ est prÃ©sent *et* $Y$ n'aurait pas Ã©tÃ© prÃ©sent si $X$ n'avait pas Ã©tÃ© prÃ©sent.
Cette dÃ©finition requiert une notion de ce qui aurait pu arriver, mais ne s'est pas produit.[^2]
De mÃªme, l'"effet" de $X$ sur $Y$ est considÃ©rÃ© comme la diffÃ©rence entre la valeur que $Y$ aurait prise Ã©tant donnÃ© une valeur de $X$ et la valeur que $Y$ aurait prise Ã©tant donnÃ© une autre valeur de $X$.
En raison de l'accent mis sur les diffÃ©rences entre les rÃ©sultats, cette approche est parfois appelÃ©e approche "des diffÃ©rences"Â ou "contrefactuelle" de la causalitÃ©.

__Technical Note:__

Les statisticiens emploient le framework des "rÃ©sultats potentiels" pour dÃ©crire les relations contrefactuelles.
Dans ce cadre, $Y_i(1)$ dÃ©signe le rÃ©sultat pour l'unitÃ© $i$ qui serait observÃ© sous une condition (par exemple, si l'unitÃ© $i$ recevait un traitement)
et $Y_i(0)$ dÃ©signe le rÃ©sultat qui serait Ãªtre observÃ© dans une autre condition (par exemple, si l'unitÃ© $i$ n'a pas reÃ§u le traitement).
Un effet causal du traitement pour l'unitÃ© $i$ pourrait Ãªtre une simple diffÃ©rence des rÃ©sultats potentiels $Ï„_i=Y_i(1)âˆ’Y_i(0)$.
Un traitement a un effet causal (positif ou nÃ©gatif) sur $Y$ pour l'unitÃ© $i$ si $Y_i(1)â‰ Y_i(0)$.

[^2]: Holland, Paul W. "Statistics and causal inference." Journal of the American Statistical Association 81.396 (1986): 945-960.

2. Point de causalitÃ© sans manipulation.
==
La dÃ©finition Â« contrefactuelle Â» de la causalitÃ© exige que l'on soit capable de rÃ©flÃ©chir aux rÃ©sultats qui peuvent entraÃ®ner des conditions diffÃ©rentes.
Ã€ quoi ressembleraient les choses si un parti plutÃ´t qu'un autre Ã©tait Ã©lu?
Les dÃ©clarations causales de tous les jours ne rÃ©pondent souvent pas Ã  cette exigence de l'une des deux maniÃ¨res suivantes.

* PremiÃ¨rement, certaines dÃ©clarations ne prÃ©cisent pas de conditions contrefactuelles claires.
Par exemple, l'affirmation selon laquelle Â« la rÃ©cession a Ã©tÃ© causÃ©e par Wall Street Â» n'indique pas un contrefactuel Ã©vident
--- devons-nous examiner s'il y aurait eu une rÃ©cession si Wall Street n'avait pas existÃ© ?
Ou la dÃ©claration est-elle vraiment une dÃ©claration sur des actions particuliÃ¨res que Wall Street aurait pu prendre mais n'a pas fait.
Si oui, quelles actions ? La validitÃ© de telles dÃ©clarations est difficile Ã  Ã©valuer et peut dÃ©pendre des conditions contrefactuelles impliquÃ©es par une dÃ©claration.

* DeuxiÃ¨mement, certaines dÃ©clarations impliquent des conditions contrefactuelles qui ne peuvent Ãªtre imaginÃ©es.
Par exemple, l'affirmation selon laquelle Peter a obtenu le poste parce qu'il est Peter implique une considÃ©ration de ce qui se serait passÃ© si Peter n'Ã©tait pas Peter.
Alternativement, l'affirmation selon laquelle Peter a obtenu le poste parce qu'il est un homme nÃ©cessite de considÃ©rer Peter comme autre qu'un homme.
Le problÃ¨me est que les contrefactuels dans ces cas impliquent un changement non seulement dans la condition Ã  laquelle fait face un individu, mais dans l'individu lui-mÃªme.

Pour Ã©viter de tels problÃ¨mes, certains statisticiens recommandent de restreindre les  assertions de causalitÃ© aux traitements qui peuvent en thÃ©orie (pas nÃ©cessairement en pratique) Ãªtre manipulÃ©s.[^11]
Par exemple, alors que nous pourrions avoir des difficultÃ©s avec l'affirmation selon laquelle Peter a obtenu le poste parce qu'il Ã©tait un homme, nous n'avons pas de telles difficultÃ©s avec l'affirmation selon laquelle Peter a obtenu le poste parce que l'agence de recrutement pensait qu'il Ã©tait un homme.

[^11]: Holland, Paul W. "Statistics and causal inference." Journal of the American Statistical Association 81.396 (1986): 945-960.

3. Les causes ne sont pas rivales.
==

MÃªme si nous pouvons nous concentrer sur l'effet d'une seule cause $X$ sur un rÃ©sultat $Y$, nous ne nous attendons gÃ©nÃ©ralement pas Ã  ce qu'il n'y ait jamais qu'une seule cause de $Y$.[^5]
De plus, si vous additionnez les effets causaux de diffÃ©rentes causes, il n'y a aucune raison de s'attendre Ã  ce qu'ils totalisent 100 %.
Par consÃ©quent, il ne sert Ã  rien d'essayer de Â«Â rÃ©partirÂ Â» les rÃ©sultats entre diffÃ©rents facteurs de causalitÃ©.
En d'autres termes, les causes ne sont pas rivales.
La National Rifle Association soutient, par exemple, que les armes Ã  feu ne tuent pas les gens, les gens tuent les gens.
Cette dÃ©claration n'a pas beaucoup de sens dans le cadre contrefactuel.
Enlevez les armes Ã  feu et vous n'aurez pas de morts par balles.
Les armes Ã  feu sont donc une cause.
Enlevez les gens et vous n'aurez pas non plus de dÃ©cÃ¨s par balle, donc les gens sont aussi une cause.
En d'autres termes, ces deux facteurs sont simultanÃ©ment les causes des mÃªmes rÃ©sultats.

[^5]: Certains appellent cela le Â«Â problÃ¨me des causes de prodigalitÃ©Â Â».


4. $X$ peut provoquer $Y$ mÃªme si $X$ n'est pas une condition nÃ©cessaire ou une condition suffisante pour $Y$.
==
On parle souvent de relations causales en termes dÃ©terministes.
MÃªme la citation de Lewis en haut de cette page semble suggÃ©rer une relation dÃ©terministe entre les causes et les effets.
On pense parfois que les relations causales impliquent des conditions nÃ©cessaires (pour que $Y$ se produise, $X$ doit se produire); on pense parfois que de telles relations impliquent des conditions suffisantes (si $X$ se produit, alors $Y$ se produit).
Mais une fois que nous parlons d'unitÃ©s multiples, il y a au moins deux faÃ§ons de penser que $X$ cause $Y$ mÃªme si $X$ n'est ni une condition nÃ©cessaire ni une condition suffisante pour $Y$.
La premiÃ¨re consiste Ã  tout rÃ©interprÃ©ter en termes probabilistes : par $X$ cause $Y$, on entend simplement que la probabilitÃ© de $Y$ est plus Ã©levÃ©e lorsque $X$ est prÃ©sent.
Une autre consiste Ã  tenir compte des contingences --- par exemple, $X$ peut provoquer $Y$ si la condition $Z$ est prÃ©sente, mais pas dans le cas contraire.[^9]

[^9]:
Mackie a prÃ©sentÃ© l'idÃ©e de conditions dites "INSS" ("INUS" en anglais) pour capturer la dÃ©pendance des causes sur d'autres causes.
Une cause peut Ãªtre une partie *Insuffisante* mais *NÃ©cessaire* d'une condition qui est elle-mÃªme *Superflue* mais *Suffisante*.
Par exemple, composer un numÃ©ro de tÃ©lÃ©phone est un motif pour contacter quelqu'un car avoir une connexion et composer un numÃ©ro est suffisant (S) pour passer un appel tÃ©lÃ©phonique,
alors que composer seul sans connexion ne suffirait pas (I), ni avoir un connexion (N).
Il existe bien sÃ»r d'autres moyens de contacter quelqu'un sans passer d'appels tÃ©lÃ©phoniques (S).
Mackie, John L. "The cement of the universe." London: Oxford Uni (1974).

5. Le problÃ¨me fondamental d'infÃ©rence causale.
==

Si les effets causaux sont des dÃ©clarations sur la diffÃ©rence entre ce qui s'est passÃ© et ce qui aurait pu arriver, alors les effets causaux ne peuvent pas Ãªtre mesurÃ©s.
C'est une mauvaise nouvelle.
De maniÃ¨re prospective, vous pouvez organiser les choses de maniÃ¨re Ã  pouvoir observer ce qui se passe si une personne reÃ§oit un traitement ou ce qui se passe si elle ne reÃ§oit pas le traitement.
Pourtant, pour la mÃªme personne, vous ne pourrez jamais observer ces deux rÃ©sultats et donc pas non plus la diffÃ©rence entre eux.
Cette incapacitÃ© Ã  observer les effets causaux au niveau de l'unitÃ© est souvent appelÃ©e le Â« problÃ¨me fondamental de l'infÃ©rence causale Â».

6. Vous pouvez estimer l'effet causal moyen mÃªme si vous ne pouvez pas observer d'effets causaux individuels.
==

MÃªme si vous ne pouvez pas observer si $X$ cause $Y$ pour une unitÃ© donnÃ©e, il est toujours possible de dÃ©terminer si $X$ cause $Y$ en moyenne.
L'idÃ©e clÃ© ici est que l'effet causal moyen est Ã©gal Ã  la diffÃ©rence entre le rÃ©sultat moyen pour toutes les unitÃ©s si toutes les unitÃ©s Ã©taient dans la condition de contrÃ´le et le rÃ©sultat moyen pour toutes les unitÃ©s si toutes les unitÃ©s Ã©taient dans la condition de traitement.
De nombreuses stratÃ©gies d'identification causale (voir [10 stratÃ©gies pour dÃ©terminer si X a causÃ© Y](http://egap.org/resource/10-strategies-for-figuring-out-if-x-caused-y)) se concentrent sur des faÃ§ons d'en savoir plus sur ces rÃ©sultats potentiels moyens.^[__Note techniqueÂ :__ La principale idÃ©e technique est que la diffÃ©rence des moyennes est la mÃªme que la moyenne des diffÃ©rences.
C'est-Ã -dire, en utilisant "l'opÃ©rateur d'espÃ©rance", $ğ”¼(Ï„_i)=ğ”¼(Y_i(1)âˆ’Y_i(0))=ğ”¼(Y_i(1))âˆ’ğ”¼(Y_i(0))$.
Les termes Ã  l'intÃ©rieur de l'opÃ©rateur d'espÃ©rance dans la deuxiÃ¨me quantitÃ© ne peuvent pas Ãªtre estimÃ©s, mais les termes Ã  l'intÃ©rieur des opÃ©rateurs d'attentes dans la troisiÃ¨me quantitÃ© peuvent l'Ãªtre.[^3] Voir l'illustration [ici](https://raw.githubusercontent.com/egap/ methodes-guides/master/causal-inference/PO.jpg).]

[10 choses Ã  savoir sur les tests d'hypothÃ¨se] (https://egap.org/resource/10-things-to-know-about-hypothesis-testing/) dÃ©crit comment on peut en savoir plus sur les effets causaux individuels plutÃ´t que sur les effets causaux moyens Ã©tant donnÃ© le problÃ¨me fondamental de l'infÃ©rence causale.

[^3]: Holland, Paul W. "Statistics and causal inference." Journal of the American Statistical Association 81.396 (1986): 945-960.

7. L'estimation de l'effet causal moyen ne nÃ©cessite pas que les groupes de traitement et de contrÃ´le soient identiques.
==
Une stratÃ©gie que les gens utilisent pour en savoir plus sur l'effet causal moyen consiste Ã  crÃ©er des groupes de traitement et de contrÃ´le par randomisation (voir [10 StratÃ©gies pour dÃ©terminer si X a causÃ© Y] (http://egap.org/resource/10-strategies-for- dÃ©terminer-si-x-causÃ©-y)).
Ce faisant, les chercheurs s'inquiÃ¨tent parfois s'ils constatent que les groupes de traitement et de contrÃ´le qui en rÃ©sultent ne se ressemblent pas selon les dimensions pertinentes.

La bonne nouvelle est que l'argument expliquant pourquoi les diffÃ©rences dans les rÃ©sultats moyens entre les groupes de traitement et de contrÃ´le assignÃ©s au hasard capturent l'effet moyen de traitement (en espÃ©rance pour des randomisations rÃ©pÃ©tÃ©es au sein du mÃªme groupe d'unitÃ©s) ne repose *pas* sur le fait que les groupes de traitement et de contrÃ´le ont des caractÃ©ristiques observÃ©es similaires.
Il repose uniquement sur l'idÃ©e que, en moyenne, les rÃ©sultats dans les groupes traitÃ©s et tÃ©moins captureront les rÃ©sultats moyens pour toutes les unitÃ©s du groupe expÃ©rimental si elles Ã©taient, respectivement, en traitement ou en contrÃ´le.
En pratique, les groupes de traitement et de contrÃ´le rÃ©els ne seront pas identiques.[^10]

[^10]: Pour cette raison, les tests-$t$ pour vÃ©rifier si "la randomisation a fonctionnÃ©" n'ont pas beaucoup de sens, du moins si vous savez qu'une procÃ©dure randomisÃ©e a Ã©tÃ© suivie --- simplement par hasard, 1 test sur 20 montrera des diffÃ©rences statistiquement dÃ©tectables entre les groupes de traitement et de contrÃ´le.
En cas de doute sur la mise en Å“uvre correcte d'une procÃ©dure randomisÃ©e, ces tests peuvent Ãªtre utilisÃ©s pour tester l'hypothÃ¨se selon laquelle les donnÃ©es ont bien Ã©tÃ© gÃ©nÃ©rÃ©es par une procÃ©dure randomisÃ©e.
Ces tests peuvent alors Ãªtre particuliÃ¨rement importants pour des expÃ©riences de terrain oÃ¹ les chaÃ®nes de communication entre la personne randomisant et la personne mettant en Å“uvre l'assignation du traitement peuvent Ãªtre longues et complexes.

8. La corrÃ©lation n'est pas la causalitÃ©.
==

Une corrÃ©lation entre $X$ et $Y$ est une dÃ©claration sur les relations entre les rÃ©sultats rÃ©els dans le monde, et non sur la relation entre les rÃ©sultats rÃ©els et les rÃ©sultats contrefactuels.
Ainsi, les dÃ©clarations sur les causes et les corrÃ©lations n'ont pas grand-chose Ã  voir les unes avec les autres.
Des corrÃ©lations positives peuvent Ãªtre cohÃ©rentes avec des effets causaux positifs, aucun effet causal ou mÃªme des effets causaux nÃ©gatifs.
Par exemple, la prise de mÃ©dicaments contre la toux est positivement corrÃ©lÃ©e Ã  la toux mais a, espÃ©rons-le, un effet causal nÃ©gatif sur la toux.^[__Note techniqueÂ :__ Soit $D_i$ un indicateur pour savoir si l'unitÃ© $i$ a reÃ§u un traitement ou non.

Alors, la diffÃ©rence de rÃ©sultats moyens entre ceux qui reÃ§oivent le traitement et ceux qui n'en reÃ§oivent pas peut s'Ã©crire $\frac{âˆ‘_i D_iÃ—Y_i(1)}{âˆ‘_iD_i}âˆ’\frac{âˆ‘_i (1âˆ’D_i)Ã— Y_i(0)}{âˆ‘_i (1âˆ’D_i)}$.
En l'absence d'informations sur la maniÃ¨re dont le traitement a Ã©tÃ© assignÃ©, nous ne pouvons pas dire si cette diffÃ©rence est un bon estimateur de l'effet moyen du traitement, c'est-Ã -dire de la diffÃ©rence entre les rÃ©sultats potentiels moyens pour les groupes de traitement et de contrÃ´le pour toutes les unitÃ©s.
Ce qui importe est de savoir si $\frac{âˆ‘_i D_iÃ—Y_i(1)}{âˆ‘_iD_i}$ est une bonne estimation de $\frac{âˆ‘_i 1Ã—Y_i(1)}{âˆ‘_i1}$ et si $\frac {âˆ‘_i (1âˆ’D_i)Ã—Y_i(0)}{âˆ‘_i (1âˆ’D_i)}$ est une bonne estimation de $\frac{âˆ‘_i 1Ã—Y_i(0)}{âˆ‘_i1}$.
Cela pourrait Ãªtre le cas si ceux qui ont reÃ§u un traitement sont un Ã©chantillon reprÃ©sentatif de toutes les unitÃ©s, mais sinon il n'y a aucune raison de s'attendre Ã  ce qu'il le soit.]

9. Si vous savez qu'en moyenne $A$ cause $B$ et $B$ cause $C$, cela ne veut pas dire qu'en moyenne $A$ cause $C$.

Vous pourriez vous attendre Ã  ce que si $A$ cause $B$ et $B$ cause $C$, alors $A$ cause $C$.[^12]
Mais il n'y a aucune raison de croire que les relations causales moyennes sont transitives de cette maniÃ¨re.
Pour voir pourquoi, imaginez que $A$ a causÃ© $B$ pour les hommes mais pas les femmes et $B$ a causÃ© $C$ pour les femmes mais pas les hommes.
Ensuite, en moyenne, $A$ cause $B$ et $B$ cause $C$, mais il se peut qu'il n'y ait toujours personne pour qui $A$ cause $C$ Ã  $B$.

[^12]: InterprÃ©tez "$A$ cause $B$, en moyenne" comme "l'effet moyen de $A$ sur $B$ est positif".

10. Il est plus facile d'en apprendre davantage sur les Â«Â effets des causesÂ Â» que d'en apprendre davantage sur les Â«Â causes des effetsÂ Â».
==

Bien que cela puisse sembler Ãªtre deux faÃ§ons de dire la mÃªme chose, il y a une diffÃ©rence entre comprendre quel est l'effet de $X$ sur $Y$ (les "effets d'une cause") et si un rÃ©sultat $Y$ Ã©tait *dÃ»* Ã  une cause $X$ (la "cause d'un effet").[^6] ConsidÃ©rez l'exemple suivant.
Supposons que nous menions une expÃ©rience avec un Ã©chantillon qui contient un nombre Ã©gal d'hommes et de femmes.
L'expÃ©rience assigne au hasard des hommes et des femmes Ã  un traitement binaire $X$ et mesure un rÃ©sultat binaire $Y$.
De plus, supposons que $X$ ait un effet positif de 1 pour tous les hommes, c'est-Ã -dire
le rÃ©sultat potentiel de contrÃ´le des hommes est de zÃ©ro ($Y_i(0) = 0$) et leur rÃ©sultat potentiel traitÃ© est de un ($Y_i(1) = 1$).
Pour toutes les femmes, $X$ a un effet nÃ©gatif de $-1$, c'est-Ã -dire que le rÃ©sultat potentiel de contrÃ´le des femmes est de un ($Y_i(0) = 1$) et leur rÃ©sultat potentiel traitÃ© est de zÃ©ro ($Y_i(1) = 0$).
Dans cet exemple, l'effet moyen de $X$ sur $Y$ est nul.
Mais pour tous les participants du groupe de traitement avec $Y=1$, il est vrai que $Y=1$ *car* $X=1$.
De mÃªme, pour tous les participants du groupe de traitement avec $Y=0$, il est vrai que $Y=0$ *car* $X=1$.
L'expÃ©rimentation peut obtenir une rÃ©ponse exacte Ã  la question sur les Â«Â effets d'une causeÂ Â», mais il n'est gÃ©nÃ©ralement pas possible d'obtenir une rÃ©ponse exacte Ã  la question sur la Â«Â cause d'un effetÂ Â».[^7]

[^6]: Certains rÃ©interprÃ¨tent la question des Â«Â causes des effetsÂ Â» comme suitÂ : quelles sont les causes qui ont des effets sur les rÃ©sultats. Voir Andrew Gelman and Guido Imbens, "Why ask why? Forward causal inference and reverse causal questions", NBER Working Paper No. 19614 (Nov. 2013).
[^7]: Voir, par exemple, Tian, J., Pearl, J. 2000. â€œProbabilities of Causation: Bounds and Identification.â€ Annals of Mathematics and Artificial Intelligence 28:287â€“313.
